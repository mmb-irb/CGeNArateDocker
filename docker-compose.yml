services:
  website:
    image: website_image   # name of website image
    hostname: my_stack_website
    build:
      context: ./website  # folder to search Dockerfile for this image
      args:
        WEBSITE_INNER_PORT: ${WEBSITE_INNER_PORT}
    depends_on:
      - mongo-seed
    ports:
      - "${WEBSITE_PORT}:${WEBSITE_INNER_PORT}"   # port mapping, be aware that the second port is the same exposed in the website/Dockerfile
    volumes:
      - ${WEBSITE_DATA_VOLUME_PATH}:/data   # path where the data generated by the website will be stored
      - ${WEBSITE_VOLUME_PATH}:/var/www/html   # path for the website code
      - "${SCRIPTS_VOLUME_PATH}/MCDNA:/scripts/MCDNA"  # path where the scripts used by the website will be stored
      - ./website/act_qmaster:/var/lib/gridengine/default/common/act_qmaster
      - ${SSH_KEYS_VOLUME_PATH}:/keys
    # networks:
    #   sgenet:
    #     ipv4_address: 172.19.0.18
    #     aliases:
    #       - my_stack_website
    #   dbnet: {}
    networks:
      - sgenet
      - dbnet
    deploy:
      replicas: ${WEBSITE_REPLICAS}   # Specify the number of replicas for Docker Swarm
      resources:
        limits:
          cpus: ${WEBSITE_CPU_LIMIT}   # Specify the limit number of CPUs
          memory: ${WEBSITE_MEMORY_LIMIT}   # Specify the limit memory
        reservations:
          cpus: ${WEBSITE_CPU_RESERVATION}   # Specify the reserved number of CPUs
          memory: ${WEBSITE_MEMORY_RESERVATION}   # Specify the reserved memory
      restart_policy:
        condition: any   # Restart always
      update_config:
        order: start-first  # Priority over other services

  workflow:
    image: workflow_image   # name of workflow image
    #Â platform: linux/amd64
    build:
      context: ./workflow  # folder to search Dockerfile for this image
    # networks:
    #   - dbnet
    volumes:
      - workflow_data:/mnt
      - workflow_scripts:/app/Scripts
    deploy:
      replicas: ${WORKFLOW_REPLICAS}  # Ensure this service is not deployed by default as it is a one-time task
      resources:
        limits:
          cpus: ${WORKFLOW_CPU_LIMIT}   # Specify the limit number of CPUs
          memory: ${WORKFLOW_MEMORY_LIMIT}   # Specify the limit memory
        reservations:
          cpus: ${WORKFLOW_CPU_RESERVATION}   # Specify the reserved number of CPUs
          memory: ${WORKFLOW_MEMORY_RESERVATION}   # Specify the reserved memory

  sge:
    image: sge_image   # name of SGE image
    hostname: my_stack_sge
    build:
      context: ./sge  # folder to search Dockerfile for this image
      args:
        DOCKER_GROUP_ID: ${DOCKER_GROUP_ID}
        SUBMITTER_HOSTNAME: ${SUBMITTER_HOSTNAME}
        SGE_SSH_PORT: ${SGE_SSH_PORT}
        SGE_PORT: ${SGE_PORT}
    # networks:
    #   sgenet:
    #     ipv4_address: 172.19.0.19
    #     aliases:
    #       - my_stack_sge
    networks:
      - sgenet
    depends_on:
      - mongo-seed
    ports:
      - "${SGE_SSH_PORT}:${SGE_SSH_PORT}"
      - "${SGE_PORT}:${SGE_PORT}"
    volumes:
      - workflow_data:/data
      - workflow_scripts:/scripts
      - /var/run/docker.sock:/var/run/docker.sock
      - ${SSH_KEYS_VOLUME_PATH}:/keys
    devices:
      - '/dev/fuse:/dev/fuse'
    cap_add:
        - SYS_ADMIN
    security_opt:
        - apparmor:unconfined
    stdin_open: true
    restart: always
    deploy:
      replicas: ${SGE_REPLICAS}  # Ensure this service is not deployed by default as it is a one-time task
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          cpus: ${SGE_CPU_LIMIT}   # Specify the limit number of CPUs
          memory: ${SGE_MEMORY_LIMIT}   # Specify the limit memory
        reservations:
          cpus: ${SGE_CPU_RESERVATION}   # Specify the reserved number of CPUs
          memory: ${SGE_MEMORY_RESERVATION}   # Specify the reserved memory

  mongodb:
    image: mongo:6
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_INITDB_ROOT_USERNAME}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_INITDB_ROOT_PASSWORD}
      MONGO_PORT: ${DB_OUTER_PORT}
      MONGO_INITDB_DATABASE: ${DB_DATABASE}
      WEBSITE_SERVER_DB_LOGIN: ${WEBSITE_DB_LOGIN}
      WEBSITE_SERVER_DB_PASSWORD: ${WEBSITE_DB_PASSWORD}
      DB_COLLECTION_WFS: ${DB_COLLECTION_WFS}
      DB_COLLECTION_PRJ: ${DB_COLLECTION_PRJ}
    ports:
      - "${DB_OUTER_PORT}:${DB_INNER_PORT}"
    volumes:
      - ${DB_VOLUME_PATH}:/data/db   # path where the database will be stored (outside the container, in the host machine)
      - ./mongodb/mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js:ro   # path to the initialization script
    networks:
      - dbnet
    deploy:
      replicas: ${DB_REPLICAS}   # Specify the number of replicas for Docker Swarm
      resources:
        limits:
          cpus: ${DB_CPU_LIMIT}    # Specify the limit number of CPUs
          memory: ${DB_MEMORY_LIMIT}   # Specify the limit memory
        reservations:
          cpus: ${DB_CPU_RESERVATION}   # Specify the reserved number of CPUs
          memory: ${DB_MEMORY_RESERVATION}   # Specify the reserved memory
      restart_policy:
        condition: on-failure   # Restart only on failure

  mongo-seed:
    image: mongo:6
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_INITDB_ROOT_USERNAME}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_INITDB_ROOT_PASSWORD}
      MONGO_PORT: ${DB_OUTER_PORT}
      MONGO_INITDB_DATABASE: ${DB_DATABASE}
      DB_HOST: ${DB_HOST}
      DB_COLLECTION_WFS: ${DB_COLLECTION_WFS}
      DB_COLLECTION_PRJ: ${DB_COLLECTION_PRJ}
    depends_on:
      - mongodb
    networks:
      - dbnet
    volumes:
      - "./mongodb/${DB_COLLECTION_WFS}.json:/${DB_COLLECTION_WFS}.json:ro"
      - "./mongodb/${DB_COLLECTION_PRJ}.json:/${DB_COLLECTION_PRJ}.json:ro"
      - ./mongodb/import.sh:/import.sh:ro
      - ${SSH_KEYS_VOLUME_PATH}:/keys
    entrypoint: ["bash", "/import.sh"]
    deploy:
      replicas: 1  # Ensures it runs only once
      restart_policy:
        condition: none  # Prevents auto-restart after completion

volumes:
  workflow_data:
    external: true
  workflow_scripts:
    external: true

networks:
  dbnet: 
    external: true   # Use an external network
  sgenet:
    external: true   # Use an external network
    # ipam:
    #   config:
    #         - subnet: 10.0.2.0/24